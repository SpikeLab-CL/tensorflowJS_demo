{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "batch = 1024\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargamos los datos del MNIST DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot de una imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x125c1d898>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[randint(0,x_train.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hacemos one hot encoding del target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2],1)\n",
    "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1], x_test.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (x_train.shape[1], x_train.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generamos nuestro modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 34s 564us/step - loss: 0.3198 - acc: 0.9020 - val_loss: 0.1469 - val_acc: 0.9588\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 34s 560us/step - loss: 0.2101 - acc: 0.9367 - val_loss: 0.1060 - val_acc: 0.9697\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 33s 554us/step - loss: 0.1685 - acc: 0.9493 - val_loss: 0.0795 - val_acc: 0.9752\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 36s 597us/step - loss: 0.1428 - acc: 0.9568 - val_loss: 0.0665 - val_acc: 0.9788\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 33s 555us/step - loss: 0.1207 - acc: 0.9636 - val_loss: 0.0654 - val_acc: 0.9789\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 35s 584us/step - loss: 0.1068 - acc: 0.9676 - val_loss: 0.0523 - val_acc: 0.9835\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 33s 557us/step - loss: 0.0984 - acc: 0.9707 - val_loss: 0.0475 - val_acc: 0.9849\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 34s 566us/step - loss: 0.0902 - acc: 0.9732 - val_loss: 0.0430 - val_acc: 0.9867\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 35s 587us/step - loss: 0.0823 - acc: 0.9748 - val_loss: 0.0405 - val_acc: 0.9880\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 34s 573us/step - loss: 0.0783 - acc: 0.9758 - val_loss: 0.0368 - val_acc: 0.9872\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 34s 571us/step - loss: 0.0738 - acc: 0.9775 - val_loss: 0.0350 - val_acc: 0.9879\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 35s 579us/step - loss: 0.0689 - acc: 0.9797 - val_loss: 0.0324 - val_acc: 0.9895\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 34s 570us/step - loss: 0.0641 - acc: 0.9811 - val_loss: 0.0299 - val_acc: 0.9907\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 35s 588us/step - loss: 0.0643 - acc: 0.9798 - val_loss: 0.0288 - val_acc: 0.9907\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 34s 573us/step - loss: 0.0608 - acc: 0.9814 - val_loss: 0.0311 - val_acc: 0.9902\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 33s 552us/step - loss: 0.0587 - acc: 0.9817 - val_loss: 0.0290 - val_acc: 0.9905\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 33s 547us/step - loss: 0.0564 - acc: 0.9829 - val_loss: 0.0274 - val_acc: 0.9907\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 35s 577us/step - loss: 0.0533 - acc: 0.9835 - val_loss: 0.0272 - val_acc: 0.9912\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 34s 573us/step - loss: 0.0516 - acc: 0.9841 - val_loss: 0.0267 - val_acc: 0.9913\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 33s 553us/step - loss: 0.0517 - acc: 0.9843 - val_loss: 0.0272 - val_acc: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10b5317f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Guardamos el model en tensorflowJS format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflowjs as tfjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfjs.converters.save_keras_model(model, \".\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:matias]",
   "language": "python",
   "name": "conda-env-matias-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
